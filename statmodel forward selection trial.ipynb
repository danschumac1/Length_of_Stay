{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ade6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "from functions.functions import forward_selection_pvalues, calculate_aic, AIC_forward_selection, remove_high_vif_features\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d377568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df_los = pd.read_pickle('./data/los_cat.pkl')\n",
    "# Drop certain columns as mentioned\n",
    "df_los = df_los.drop(\n",
    "    ['altProductLine1', 'altProductLine1SUB', 'payCode', 'LOS', 'AM-LOS', 'GM-LOS', 'patientID'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Select numerical and categorical columns correctly from df_los\n",
    "df_numerical = df_los.select_dtypes(include=[np.number])\n",
    "df_categorical = df_los.select_dtypes(exclude=[np.number])\n",
    "\n",
    "# Initialize a list to keep the variables with less than 26 unique values\n",
    "short_cats = [col for col in df_categorical.columns if len(df_los[col].unique()) < 5]\n",
    "df_categorical = df_categorical[short_cats]\n",
    "# Concatenate the filtered categorical DataFrame with the numerical DataFrame\n",
    "# Ensure var_list is used to filter df_categorical correctly\n",
    "df_los = pd.concat(\n",
    "    [pd.get_dummies(df_categorical, drop_first=True), df_numerical], axis=1)\n",
    "df_los = df_los.drop('ethnicity_Not Hispanic or Latino', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "438f1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_los is your initial DataFrame and is already loaded\n",
    "\n",
    "# # Select numerical columns\n",
    "# X_numerical = df_los.select_dtypes(include=[np.number])\n",
    "\n",
    "# # Convert categorical variables to dummy variables, excluding the first category\n",
    "# X_categorical = pd.get_dummies(df_los.select_dtypes(exclude=[np.number]), drop_first=True)\n",
    "\n",
    "# Combine numerical and dummy variables into a single DataFrame\n",
    "# df = pd.concat([X_numerical, X_categorical], axis=1)\n",
    "\n",
    "# Define your features (X) by excluding 'LOSDiscrepancyCost' from the combined DataFrame\n",
    "X = df_los.drop('LOSDiscrepancyCost', axis=1)\n",
    "\n",
    "# Define the target variable (y) as 'LOSDiscrepancyCost'\n",
    "y = df_los['LOSDiscrepancyCost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd36a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ethnicity_Hispanic or Latino</td>\n",
       "      <td>1.012296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admitType_cat_Emergency</td>\n",
       "      <td>1.754885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admitType_cat_Urgent</td>\n",
       "      <td>1.580933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hospital_cat_South Hospital</td>\n",
       "      <td>1.020427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex_cat_Male</td>\n",
       "      <td>1.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dischargeQTR</td>\n",
       "      <td>1.029282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>caseMixIndex</td>\n",
       "      <td>2.084988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diagPosCnt</td>\n",
       "      <td>1.164317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>procPosCnt</td>\n",
       "      <td>2.292358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>totalCharge</td>\n",
       "      <td>2.697747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Variable       VIF\n",
       "1   ethnicity_Hispanic or Latino  1.012296\n",
       "2        admitType_cat_Emergency  1.754885\n",
       "3           admitType_cat_Urgent  1.580933\n",
       "4    hospital_cat_South Hospital  1.020427\n",
       "5                   sex_cat_Male  1.014600\n",
       "6                   dischargeQTR  1.029282\n",
       "7                   caseMixIndex  2.084988\n",
       "8                     diagPosCnt  1.164317\n",
       "9                     procPosCnt  2.292358\n",
       "10                   totalCharge  2.697747"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Define a function to calculate VIFs for the given DataFrame\n",
    "def calculate_vifs(X_df):\n",
    "    X_df = sm.add_constant(X_df)\n",
    "    vif_data = pd.DataFrame({\n",
    "        \"Variable\": X_df.columns,\n",
    "        \"VIF\": [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
    "    })\n",
    "    return vif_data.drop(index=0)  # Drop the row corresponding to the constant\n",
    "\n",
    "# VIF threshold\n",
    "calculate_vifs(X)\n",
    "# # Iteratively remove variables with VIF above the threshold\n",
    "# print(f\"Processing {X.shape[1]} features...\")\n",
    "\n",
    "# while True:\n",
    "#     vif_data = calculate_vifs(X)\n",
    "#     max_vif = vif_data['VIF'].max()\n",
    "#     if max_vif > vif_threshold:\n",
    "#         variable_to_drop = vif_data[vif_data['VIF'] == max_vif]['Variable'].values[0]\n",
    "#         print(f\"Dropping '{variable_to_drop}' with VIF={max_vif:.2f}\")\n",
    "#         X = X.drop(columns=[variable_to_drop])\n",
    "#     else:\n",
    "#         print(\"No variables with VIF above the threshold. Stopping iteration.\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85da58",
   "metadata": {},
   "source": [
    "### Forward Selection P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6798ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding caseMixIndex with p-value 0.0\n",
      "Adding admitType_cat_Emergency with p-value 2.0704917408270804e-175\n",
      "Adding admitType_cat_Urgent with p-value 6.906560474626964e-103\n",
      "Adding diagPosCnt with p-value 3.560988724504582e-50\n",
      "Adding procPosCnt with p-value 1.894179712792939e-51\n",
      "Adding dischargeQTR with p-value 9.489245073222655e-16\n",
      "Adding totalCharge with p-value 6.438520958001528e-08\n",
      "Adding Q(\"hospital_cat_South Hospital\") with p-value 6.791067759731851e-06\n",
      "Adding Q(\"ethnicity_Hispanic or Latino\") with p-value 4.344699574543411e-05\n",
      "Adding sex_cat_Male with p-value 0.013885250612856075\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     LOSDiscrepancyCost   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     2398.\n",
      "Date:                Thu, 28 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        12:12:57   Log-Likelihood:                -67695.\n",
      "No. Observations:                8123   AIC:                         1.354e+05\n",
      "Df Residuals:                    8112   BIC:                         1.355e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                           -26.0800     52.577     -0.496      0.620    -129.144      76.984\n",
      "caseMixIndex                       1461.9063     12.851    113.761      0.000    1436.716    1487.097\n",
      "admitType_cat_Emergency            1230.5581     42.399     29.023      0.000    1147.445    1313.671\n",
      "admitType_cat_Urgent               1237.1821     62.519     19.789      0.000    1114.629    1359.735\n",
      "diagPosCnt                           32.7934      1.855     17.681      0.000      29.158      36.429\n",
      "procPosCnt                          -77.2566      7.216    -10.706      0.000     -91.402     -63.111\n",
      "dischargeQTR                         76.6923      9.799      7.826      0.000      57.483      95.901\n",
      "totalCharge                          -0.0018      0.000     -5.079      0.000      -0.002      -0.001\n",
      "Q(\"hospital_cat_South Hospital\")    130.3915     28.315      4.605      0.000      74.887     185.896\n",
      "Q(\"ethnicity_Hispanic or Latino\")   159.9881     38.747      4.129      0.000      84.034     235.942\n",
      "sex_cat_Male                         56.2272     22.850      2.461      0.014      11.436     101.018\n",
      "==============================================================================\n",
      "Omnibus:                     3081.084   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            48567.957\n",
      "Skew:                          -1.391   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.651   Cond. No.                     5.29e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.29e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "data = df_los\n",
    "dependent_var = 'LOSDiscrepancyCost'\n",
    "predictors = [f'Q(\"{col}\")' if ' ' in col else col for col in X.columns if col != dependent_var]\n",
    "\n",
    "# dependent_var = 'Y'\n",
    "# predictors = ['Q(\"APR DRG\")', 'X']  # Note how the variable with a space is quoted\n",
    "formula = f\"{dependent_var} ~ {' + '.join(predictors)}\"\n",
    "\n",
    "forward_p_model = forward_selection_pvalues(data, dependent_var, predictors)\n",
    "print(forward_p_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14890c",
   "metadata": {},
   "source": [
    "### Forward Selection AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2c14df8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added caseMixIndex, AIC: 137243.33114628686\n",
      "Added admitType_cat_Emergency, AIC: 136447.6739802406\n",
      "Added admitType_cat_Urgent, AIC: 135985.54489221965\n",
      "Added diagPosCnt, AIC: 135765.53869909473\n",
      "Added procPosCnt, AIC: 135539.65856684028\n",
      "Added dischargeQTR, AIC: 135477.0651703751\n",
      "Added totalCharge, AIC: 135449.80783719243\n",
      "Added Q(\"hospital_cat_South Hospital\"), AIC: 135431.53292066738\n",
      "Added Q(\"ethnicity_Hispanic or Latino\"), AIC: 135416.79675854123\n",
      "Added sex_cat_Male, AIC: 135412.73550308196\n",
      "No more predictors to evaluate.\n",
      "Final model formula: LOSDiscrepancyCost ~ caseMixIndex + admitType_cat_Emergency + admitType_cat_Urgent + diagPosCnt + procPosCnt + dischargeQTR + totalCharge + Q(\"hospital_cat_South Hospital\") + Q(\"ethnicity_Hispanic or Latino\") + sex_cat_Male\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     LOSDiscrepancyCost   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     2398.\n",
      "Date:                Thu, 28 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        12:15:12   Log-Likelihood:                -67695.\n",
      "No. Observations:                8123   AIC:                         1.354e+05\n",
      "Df Residuals:                    8112   BIC:                         1.355e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                           -26.0800     52.577     -0.496      0.620    -129.144      76.984\n",
      "caseMixIndex                       1461.9063     12.851    113.761      0.000    1436.716    1487.097\n",
      "admitType_cat_Emergency            1230.5581     42.399     29.023      0.000    1147.445    1313.671\n",
      "admitType_cat_Urgent               1237.1821     62.519     19.789      0.000    1114.629    1359.735\n",
      "diagPosCnt                           32.7934      1.855     17.681      0.000      29.158      36.429\n",
      "procPosCnt                          -77.2566      7.216    -10.706      0.000     -91.402     -63.111\n",
      "dischargeQTR                         76.6923      9.799      7.826      0.000      57.483      95.901\n",
      "totalCharge                          -0.0018      0.000     -5.079      0.000      -0.002      -0.001\n",
      "Q(\"hospital_cat_South Hospital\")    130.3915     28.315      4.605      0.000      74.887     185.896\n",
      "Q(\"ethnicity_Hispanic or Latino\")   159.9881     38.747      4.129      0.000      84.034     235.942\n",
      "sex_cat_Male                         56.2272     22.850      2.461      0.014      11.436     101.018\n",
      "==============================================================================\n",
      "Omnibus:                     3081.084   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            48567.957\n",
      "Skew:                          -1.391   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.651   Cond. No.                     5.29e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.29e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "def calculate_aic(model):\n",
    "    return model.aic\n",
    "\n",
    "base_formula = f'{dependent_var} ~ 1'  # Model with only intercept\n",
    "base_model = ols(base_formula, data=data).fit()\n",
    "current_aic = calculate_aic(base_model)\n",
    "\n",
    "predictors = [f'Q(\"{col}\")' if ' ' in col else col for col in X.columns if col != dependent_var]\n",
    "\n",
    "\n",
    "while True:\n",
    "    aic_with_candidates = []\n",
    "    for predictor in predictors:\n",
    "        # Try adding each remaining predictor to the selected predictors and calculate AIC\n",
    "        formula = f\"{dependent_var} ~ {' + '.join(selected_predictors + [predictor])}\"\n",
    "        model = ols(formula, data=data).fit()\n",
    "        aic_with_candidates.append((calculate_aic(model), predictor))\n",
    "    \n",
    "    # Check if there are no more predictors to evaluate\n",
    "    if not aic_with_candidates:\n",
    "        print(\"No more predictors to evaluate.\")\n",
    "        break\n",
    "\n",
    "    # Find the predictor that, when added, results in the lowest AIC\n",
    "    aic_with_candidates.sort()\n",
    "    best_new_aic, best_new_predictor = aic_with_candidates[0]\n",
    "    \n",
    "    # If adding the new variable lowers the AIC, update the model and continue\n",
    "    if best_new_aic < current_aic:\n",
    "        predictors.remove(best_new_predictor)\n",
    "        selected_predictors.append(best_new_predictor)\n",
    "        current_aic = best_new_aic\n",
    "        print(f\"Added {best_new_predictor}, AIC: {best_new_aic}\")\n",
    "    else:\n",
    "        # If no improvement, stop the loop\n",
    "        break\n",
    "\n",
    "# Final model\n",
    "final_formula = f\"{dependent_var} ~ {' + '.join(selected_predictors)}\"\n",
    "final_model = ols(final_formula, data=data).fit()\n",
    "print(f\"Final model formula: {final_formula}\")\n",
    "print(final_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5b9777a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m rf_reg \u001b[38;5;241m=\u001b[39m RandomForestRegressor(max_features\u001b[38;5;241m=\u001b[39mmax_features, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39mtree_count)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mrf_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# make predictions\u001b[39;00m\n\u001b[0;32m     36\u001b[0m rf_preds \u001b[38;5;241m=\u001b[39m rf_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model for prediction\n",
    "# GET EACH STOCK INDIVIDUALLY\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "results_dict = {'DT_MSE':[], 'RF_MSE': [], 'LR_MSE':[], 'SVR_MSE': []}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3)\n",
    "\n",
    "# FIT DECISION TREE\n",
    "# get features needed\n",
    "max_features = X_train.shape[1]\n",
    "tree_count = 1000\n",
    "\n",
    "# set up model\n",
    "dc_reg = DecisionTreeRegressor(max_features=max_features, random_state=27)\n",
    "#fit mode\n",
    "dc_reg.fit(X_train, y_train)\n",
    "# make predictions\n",
    "dt_preds = dc_reg.predict(X_test)\n",
    "# get mse\n",
    "dt_mse = mean_squared_error(y_test, dt_preds)\n",
    "\n",
    "# FIT RANDOM FOREST\n",
    "# set up model\n",
    "rf_reg = RandomForestRegressor(max_features=max_features, random_state=27, n_estimators=tree_count)\n",
    "# fit model\n",
    "rf_reg.fit(X_train, y_train)\n",
    "# make predictions\n",
    "rf_preds = rf_reg.predict(X_test)\n",
    "# get mse\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "\n",
    "# FIT LINEAR REGRESSION\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "lr_preds = lr_reg.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb03513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10.0, 'epsilon': 0.1}\n",
      "Best estimator: SVR(C=10.0)\n"
     ]
    }
   ],
   "source": [
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'epsilon': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svr_reg = SVR()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(svr_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)  \n",
    "\n",
    "# Retrieve the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best estimator:\", best_estimator)\n",
    "\n",
    "# FIT SUPPORT VECTOR REGRESSION\n",
    "# scale for svr\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "svr_reg = SVR(C = best_params['C'], epsilon = best_params['epsilon']) \n",
    "svr_reg.fit(X_train_scaled, y_train)\n",
    "svr_preds = svr_reg.predict(X_test_scaled)\n",
    "svr_mse = mean_squared_error(y_test, svr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf984485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPEND RESULTS\n",
    "# name\n",
    "# decesion tree\n",
    "results_dict['DT_MSE'].append(dt_mse)\n",
    "# random forest\n",
    "results_dict['RF_MSE'].append(rf_mse)\n",
    "# linear regression\n",
    "results_dict['LR_MSE'].append(lr_mse)\n",
    "# svr\n",
    "results_dict['SVR_MSE'].append(svr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26231950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT_MSE</th>\n",
       "      <td>4.586321e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_MSE</th>\n",
       "      <td>2.529429e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_MSE</th>\n",
       "      <td>9.268402e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_MSE</th>\n",
       "      <td>2.839455e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "DT_MSE   4.586321e+05\n",
       "RF_MSE   2.529429e+05\n",
       "LR_MSE   9.268402e+05\n",
       "SVR_MSE  2.839455e+06"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff754bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
